{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = \"https://www.dropbox.com/scl/fo/5w0a14icfv4o7t0azrqda/AHECd04T6OAUwcvxwiZXw-4/data/tmall?rlkey=qhx7csgahlcbuppjx4ewa3l0o&subfolder_nav_tracking=1&st=kqkod5je&dl=1\"\n",
    "output_path = \"tmall.zip\"\n",
    "\n",
    "print(\"Downloading...\")\n",
    "urllib.request.urlretrieve(url, output_path)\n",
    "print(\"Download complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile as zip\n",
    "import os\n",
    "\n",
    "with zip.ZipFile(output_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"tmall_data\")\n",
    "print(\"Extraction complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T06:30:27.508733Z",
     "iopub.status.busy": "2025-12-23T06:30:27.508433Z",
     "iopub.status.idle": "2025-12-23T06:30:27.829076Z",
     "shell.execute_reply": "2025-12-23T06:30:27.828523Z",
     "shell.execute_reply.started": "2025-12-23T06:30:27.508708Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_nodes = pd.read_csv(\"tmall_data/node2label.txt\", sep=r'\\s+', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T06:30:32.616980Z",
     "iopub.status.busy": "2025-12-23T06:30:32.616725Z",
     "iopub.status.idle": "2025-12-23T06:30:32.654576Z",
     "shell.execute_reply": "2025-12-23T06:30:32.653974Z",
     "shell.execute_reply.started": "2025-12-23T06:30:32.616958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user       81380\n",
       "product        5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes.columns=['user','product']\n",
    "\n",
    "df_nodes.head()\n",
    "df_nodes.shape\n",
    "df_nodes.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges = pd.read_csv(\"tmall_data/tmall.txt\", sep=r'\\s+', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source_node    100000\n",
       "target_node    477314\n",
       "weight            186\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edges.columns=['source_node','target_node','weight']\n",
    "\n",
    "df_edges.head()\n",
    "df_edges.shape\n",
    "df_edges.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement GNN and GCN using torch geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert edges**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T06:43:20.273115Z",
     "iopub.status.busy": "2025-12-23T06:43:20.272808Z",
     "iopub.status.idle": "2025-12-23T06:43:20.286315Z",
     "shell.execute_reply": "2025-12-23T06:43:20.285663Z",
     "shell.execute_reply.started": "2025-12-23T06:43:20.273091Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\S.Soudeep\\Documents\\Contrastive_Spiking_Graph_NeuralNetwork\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index=torch.tensor(df_edges[['source_node','target_node']].values.T, dtype=torch.long)\n",
    "edge_weight=torch.tensor(df_edges['weight'].values, dtype=torch.float)\n",
    "\n",
    "num_nodes = max(df_edges['source_node'].max(), df_edges['target_node'].max()) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T06:43:29.872105Z",
     "iopub.status.busy": "2025-12-23T06:43:29.871634Z",
     "iopub.status.idle": "2025-12-23T06:43:30.252525Z",
     "shell.execute_reply": "2025-12-23T06:43:30.251768Z",
     "shell.execute_reply.started": "2025-12-23T06:43:29.872084Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embedding_dim = 64\n",
    "node_embeddings = nn.Embedding(num_nodes, embedding_dim)\n",
    "x=node_embeddings.weight\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_weight)\n",
    "\n",
    "num_nodes = data.num_nodes\n",
    "\n",
    "peram = torch.randperm(num_nodes)\n",
    "train_size = int(0.6*num_nodes)\n",
    "val_size = int(0.2*num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T06:43:39.303589Z",
     "iopub.status.busy": "2025-12-23T06:43:39.303307Z",
     "iopub.status.idle": "2025-12-23T06:43:39.309160Z",
     "shell.execute_reply": "2025-12-23T06:43:39.308520Z",
     "shell.execute_reply.started": "2025-12-23T06:43:39.303560Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "data.test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "\n",
    "data.train_mask[peram[:train_size]] = True\n",
    "data.val_mask[peram[train_size:train_size+val_size]] = True\n",
    "data.test_mask[peram[train_size+val_size:]]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T06:44:04.658119Z",
     "iopub.status.busy": "2025-12-23T06:44:04.657367Z",
     "iopub.status.idle": "2025-12-23T06:44:04.661485Z",
     "shell.execute_reply": "2025-12-23T06:44:04.660789Z",
     "shell.execute_reply.started": "2025-12-23T06:44:04.658088Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned labels: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
      "Shape: torch.Size([577314])\n"
     ]
    }
   ],
   "source": [
    "num_nodes=data.x.shape[0]\n",
    "\n",
    "data.y = torch.randint(0,2,(num_nodes,), dtype=torch.long)\n",
    "\n",
    "print(\"Assigned labels:\", data.y[:10])\n",
    "print(\"Shape:\",data.y.shape)\n",
    "\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "\n",
    "transform = RandomNodeSplit(split='random', num_val=0.2, num_test=0.2)\n",
    "data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T06:45:39.936681Z",
     "iopub.status.busy": "2025-12-23T06:45:39.936395Z",
     "iopub.status.idle": "2025-12-23T06:45:39.942070Z",
     "shell.execute_reply": "2025-12-23T06:45:39.941484Z",
     "shell.execute_reply.started": "2025-12-23T06:45:39.936659Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T06:45:42.808237Z",
     "iopub.status.busy": "2025-12-23T06:45:42.807943Z",
     "iopub.status.idle": "2025-12-23T06:46:32.020440Z",
     "shell.execute_reply": "2025-12-23T06:46:32.019738Z",
     "shell.execute_reply.started": "2025-12-23T06:45:42.808213Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss.item()\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m200\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     loss_value = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     12\u001b[39m model.train()\n\u001b[32m     13\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m loss = F.nll_loss(output[data.train_mask], data.y[data.train_mask])\n\u001b[32m     16\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S.Soudeep\\Documents\\Contrastive_Spiking_Graph_NeuralNetwork\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S.Soudeep\\Documents\\Contrastive_Spiking_Graph_NeuralNetwork\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mGCN.forward\u001b[39m\u001b[34m(self, x, edge_index)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     x = F.relu(x)\n\u001b[32m     14\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.conv2(x, edge_index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S.Soudeep\\Documents\\Contrastive_Spiking_Graph_NeuralNetwork\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S.Soudeep\\Documents\\Contrastive_Spiking_Graph_NeuralNetwork\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S.Soudeep\\Documents\\Contrastive_Spiking_Graph_NeuralNetwork\\.venv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:241\u001b[39m, in \u001b[36mGCNConv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight)\u001b[39m\n\u001b[32m    239\u001b[39m cache = \u001b[38;5;28mself\u001b[39m._cached_edge_index\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     edge_index, edge_weight = \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cached:\n\u001b[32m    245\u001b[39m         \u001b[38;5;28mself\u001b[39m._cached_edge_index = (edge_index, edge_weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S.Soudeep\\Documents\\Contrastive_Spiking_Graph_NeuralNetwork\\.venv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:99\u001b[39m, in \u001b[36mgcn_norm\u001b[39m\u001b[34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[39m\n\u001b[32m     96\u001b[39m num_nodes = maybe_num_nodes(edge_index, num_nodes)\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     edge_index, edge_weight = \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m     edge_weight = torch.ones((edge_index.size(\u001b[32m1\u001b[39m), ), dtype=dtype,\n\u001b[32m    104\u001b[39m                              device=edge_index.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S.Soudeep\\Documents\\Contrastive_Spiking_Graph_NeuralNetwork\\.venv\\Lib\\site-packages\\torch_geometric\\utils\\loop.py:624\u001b[39m, in \u001b[36madd_remaining_self_loops\u001b[39m\u001b[34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[39m\n\u001b[32m    591\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Adds remaining self-loop :math:`(i,i) \\in \\mathcal{E}` to every node\u001b[39;00m\n\u001b[32m    592\u001b[39m \u001b[33;03m:math:`i \\in \\mathcal{V}` in the graph given by :attr:`edge_index`.\u001b[39;00m\n\u001b[32m    593\u001b[39m \u001b[33;03mIn case the graph is weighted or has multi-dimensional edge features\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    621\u001b[39m \u001b[33;03m    tensor([0.5000, 0.5000, 1.0000, 1.0000]))\u001b[39;00m\n\u001b[32m    622\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    623\u001b[39m N = maybe_num_nodes(edge_index, num_nodes)\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m mask = \u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    626\u001b[39m device = edge_index.device\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "model = GCN(hidden_channels=64, in_channels=64, out_channels=2)\n",
    "data = data\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train_model():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, data.edge_index)\n",
    "    loss = F.nll_loss(output[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "for epoch in range(200):\n",
    "    loss_value = train_model()\n",
    "    print(f'Epoch: {epoch+1:03d}, Loss: {loss_value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T06:46:36.522462Z",
     "iopub.status.busy": "2025-12-23T06:46:36.521725Z",
     "iopub.status.idle": "2025-12-23T06:46:36.639770Z",
     "shell.execute_reply": "2025-12-23T06:46:36.639121Z",
     "shell.execute_reply.started": "2025-12-23T06:46:36.522433Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m model.eval()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m.argmax(dim=\u001b[32m1\u001b[39m)\n\u001b[32m      3\u001b[39m correct = pred[data.test_mask] == data.y[data.test_mask]\n\u001b[32m      4\u001b[39m acc = \u001b[38;5;28mint\u001b[39m(correct.sum()) / \u001b[38;5;28mint\u001b[39m(data.test_mask.sum())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S.Soudeep\\Documents\\Contrastive_Spiking_Graph_NeuralNetwork\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S.Soudeep\\Documents\\Contrastive_Spiking_Graph_NeuralNetwork\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mGCN.forward\u001b[39m\u001b[34m(self, x, edge_index)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     x = F.relu(x)\n\u001b[32m     14\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.conv2(x, edge_index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S.Soudeep\\Documents\\Contrastive_Spiking_Graph_NeuralNetwork\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S.Soudeep\\Documents\\Contrastive_Spiking_Graph_NeuralNetwork\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S.Soudeep\\Documents\\Contrastive_Spiking_Graph_NeuralNetwork\\.venv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:241\u001b[39m, in \u001b[36mGCNConv.forward\u001b[39m\u001b[34m(self, x, edge_index, edge_weight)\u001b[39m\n\u001b[32m    239\u001b[39m cache = \u001b[38;5;28mself\u001b[39m._cached_edge_index\n\u001b[32m    240\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     edge_index, edge_weight = \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cached:\n\u001b[32m    245\u001b[39m         \u001b[38;5;28mself\u001b[39m._cached_edge_index = (edge_index, edge_weight)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S.Soudeep\\Documents\\Contrastive_Spiking_Graph_NeuralNetwork\\.venv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:99\u001b[39m, in \u001b[36mgcn_norm\u001b[39m\u001b[34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[39m\n\u001b[32m     96\u001b[39m num_nodes = maybe_num_nodes(edge_index, num_nodes)\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     edge_index, edge_weight = \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    103\u001b[39m     edge_weight = torch.ones((edge_index.size(\u001b[32m1\u001b[39m), ), dtype=dtype,\n\u001b[32m    104\u001b[39m                              device=edge_index.device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\S.Soudeep\\Documents\\Contrastive_Spiking_Graph_NeuralNetwork\\.venv\\Lib\\site-packages\\torch_geometric\\utils\\loop.py:624\u001b[39m, in \u001b[36madd_remaining_self_loops\u001b[39m\u001b[34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[39m\n\u001b[32m    591\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Adds remaining self-loop :math:`(i,i) \\in \\mathcal{E}` to every node\u001b[39;00m\n\u001b[32m    592\u001b[39m \u001b[33;03m:math:`i \\in \\mathcal{V}` in the graph given by :attr:`edge_index`.\u001b[39;00m\n\u001b[32m    593\u001b[39m \u001b[33;03mIn case the graph is weighted or has multi-dimensional edge features\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    621\u001b[39m \u001b[33;03m    tensor([0.5000, 0.5000, 1.0000, 1.0000]))\u001b[39;00m\n\u001b[32m    622\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    623\u001b[39m N = maybe_num_nodes(edge_index, num_nodes)\n\u001b[32m--> \u001b[39m\u001b[32m624\u001b[39m mask = \u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    626\u001b[39m device = edge_index.device\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.jit.is_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: no kernel image is available for execution on the device\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred = model(data.x, data.edge_index).argmax(dim=1)\n",
    "correct = pred[data.test_mask] == data.y[data.test_mask]\n",
    "acc = int(correct.sum()) / int(data.test_mask.sum())\n",
    "print(f'Test Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uporer toko done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all the dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch_geometric.datasets import DBLP\n",
    "from torch_geometric.data import Data, HeteroData\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.utils import dropout_edge\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "training_ratios = [0.4, 0.6, 0.8]\n",
    "num_runs = 5\n",
    "epochs = 500\n",
    "hidden_dim = 256\n",
    "time_steps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# AFTER (corrected)\n",
    "edges_file_path = \"/kaggle/working/tmall/tmall.txt\"\n",
    "nodes_file_path = \"/kaggle/working/tmall/node2label.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# During node/edge processing\n",
    "current_idx = 0\n",
    "node_id_to_idx = {}\n",
    "labels = []\n",
    "\n",
    "# 1. Process node2label.txt\n",
    "with open(nodes_file_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        node_id, label = map(int, line.strip().split())\n",
    "        if node_id not in node_id_to_idx:\n",
    "            node_id_to_idx[node_id] = current_idx\n",
    "            labels.append(label)\n",
    "            current_idx += 1\n",
    "\n",
    "# 2. Process edges and add missing nodes\n",
    "edges = []\n",
    "with open(edges_file_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        src, dst = map(int, parts[:2])\n",
    "        \n",
    "        # Add missing nodes with label -1\n",
    "        for node in [src, dst]:\n",
    "            if node not in node_id_to_idx:\n",
    "                node_id_to_idx[node] = current_idx\n",
    "                labels.append(-1)\n",
    "                current_idx += 1\n",
    "                \n",
    "        edges.append([node_id_to_idx[src], node_id_to_idx[dst]])\n",
    "\n",
    "# 3. Final checks\n",
    "assert len(node_id_to_idx) == len(labels), \"Node count mismatch!\"\n",
    "assert max(node_id_to_idx.values()) == len(node_id_to_idx) - 1, \"Indexing error\"\n",
    "\n",
    "# 4. Create tensors\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "x = torch.arange(len(node_id_to_idx), dtype=torch.float).view(-1, 1)\n",
    "y = torch.tensor(labels, dtype=torch.long)\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# or:\n",
    "# data = Data(x=x, edge_index=edge_index, y=y).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Verify node indices in edges\n",
    "assert data.edge_index.max() < data.num_nodes, \\\n",
    "    f\"Edge contains invalid node index {data.edge_index.max()} (num_nodes={data.num_nodes})\"\n",
    "\n",
    "# Check 2: Verify tensor dimensions\n",
    "print(f\"Node features: {data.x.shape}\")\n",
    "print(f\"Max node index: {data.edge_index.max().item()}\")\n",
    "print(f\"Number of nodes: {data.num_nodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T08:32:44.848981Z",
     "iopub.status.busy": "2025-08-28T08:32:44.848754Z",
     "iopub.status.idle": "2025-08-28T08:32:44.852686Z",
     "shell.execute_reply": "2025-08-28T08:32:44.851982Z",
     "shell.execute_reply.started": "2025-08-28T08:32:44.848966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T08:32:49.137999Z",
     "iopub.status.busy": "2025-08-28T08:32:49.137480Z",
     "iopub.status.idle": "2025-08-28T08:32:49.156264Z",
     "shell.execute_reply": "2025-08-28T08:32:49.155558Z",
     "shell.execute_reply.started": "2025-08-28T08:32:49.137974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.utils import dropout_edge\n",
    "import random\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# ====== ADDED MISSING COMPONENTS ======\n",
    "class TemporalAttention(nn.Module):\n",
    "    def __init__(self, time_steps):\n",
    "        super().__init__()\n",
    "        self.attention_weights = nn.Parameter(torch.randn(time_steps))\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (time_steps, num_nodes, features)\n",
    "        alpha = self.softmax(self.attention_weights)\n",
    "        weighted = alpha.unsqueeze(-1).unsqueeze(-1) * x\n",
    "        return weighted.sum(dim=0)\n",
    "\n",
    "class DynamicWeight(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.tensor([0.5]))\n",
    "\n",
    "    def forward(self, cls_loss, cont_loss):\n",
    "        return self.alpha * cls_loss + (1 - self.alpha) * cont_loss\n",
    "# ======================================\n",
    "\n",
    "class LIFNeuron(nn.Module):\n",
    "    def __init__(self, decay=0.95, threshold=1.0):\n",
    "        super().__init__()\n",
    "        self.decay = decay\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def forward(self, x, membrane=None):\n",
    "        if membrane is None:\n",
    "            membrane = torch.zeros_like(x)\n",
    "        \n",
    "        membrane = self.decay * membrane + x\n",
    "        spike = torch.sigmoid(5*(membrane - self.threshold))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            reset = (spike > 0.5).float() * self.threshold\n",
    "            membrane = membrane - reset\n",
    "            \n",
    "        return spike, membrane\n",
    "\n",
    "class SpikingGCN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, time_steps):\n",
    "        super().__init__()\n",
    "        self.conv = GCNConv(in_channels, out_channels)\n",
    "        self.lif = LIFNeuron()\n",
    "        self.time_steps = time_steps\n",
    "        self.temp_attn = TemporalAttention(time_steps)  # Now defined\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv(x, edge_index)\n",
    "        spikes = []\n",
    "        membrane = None\n",
    "        \n",
    "        for _ in range(self.time_steps):\n",
    "            spike, membrane = self.lif(x, membrane)\n",
    "            spikes.append(spike)\n",
    "            \n",
    "        return self.temp_attn(torch.stack(spikes))\n",
    "\n",
    "class DyC_DGNN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, time_steps):\n",
    "        super().__init__()\n",
    "        self.spike_gcn1 = SpikingGCN(in_channels, hidden_channels, time_steps)\n",
    "        self.spike_gcn2 = SpikingGCN(hidden_channels, hidden_channels, time_steps)\n",
    "        \n",
    "        self.proj_head = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Linear(hidden_channels, out_channels)\n",
    "        self.weight_module = DynamicWeight()  # Now defined\n",
    "        self.temperature = nn.Parameter(torch.tensor(0.1))\n",
    "\n",
    "    # REQUIRED FORWARD METHOD\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.spike_gcn1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        embeddings = self.spike_gcn2(x, edge_index)\n",
    "        return self.classifier(embeddings), self.proj_head(embeddings)\n",
    "\n",
    "    def contrastive_loss(self, proj, edge_index, mask):\n",
    "        masked_nodes = torch.where(mask)[0]\n",
    "        \n",
    "        # Create subgraph with proper node relabeling\n",
    "        subset, sub_edge_index, _, _ = k_hop_subgraph(\n",
    "            masked_nodes,\n",
    "            num_hops=2,\n",
    "            edge_index=edge_index,\n",
    "            relabel_nodes=True,\n",
    "            num_nodes=self.x.size(0)\n",
    "        )\n",
    "        \n",
    "        # Get subgraph features\n",
    "        sub_x = self.x[subset]\n",
    "        \n",
    "        # Augment edges\n",
    "        edge_index1, _ = dropout_edge(sub_edge_index, p=0.4)\n",
    "        edge_index2, _ = dropout_edge(sub_edge_index, p=0.4)\n",
    "        \n",
    "        # Get subgraph projections\n",
    "        _, proj1 = self.forward(sub_x, edge_index1)\n",
    "        _, proj2 = self.forward(sub_x, edge_index2)\n",
    "        \n",
    "        # Normalize and calculate loss\n",
    "        proj_sub = F.normalize(proj[subset], dim=1)\n",
    "        proj1 = F.normalize(proj1, dim=1)\n",
    "        proj2 = F.normalize(proj2, dim=1)\n",
    "        \n",
    "        logits = (proj_sub @ proj1.T) / self.temperature\n",
    "        labels = torch.arange(proj_sub.size(0), device=proj_sub.device)\n",
    "        return F.cross_entropy(logits, labels)\n",
    "\n",
    "    def full_loss(self, logits, y, proj, edge_index, mask):\n",
    "        cls_loss = F.cross_entropy(logits[mask], y[mask])\n",
    "        cont_loss = self.contrastive_loss(proj, edge_index, mask)\n",
    "        return self.weight_module(cls_loss, cont_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T08:32:54.997566Z",
     "iopub.status.busy": "2025-08-28T08:32:54.996874Z",
     "iopub.status.idle": "2025-08-28T08:32:55.006846Z",
     "shell.execute_reply": "2025-08-28T08:32:55.006139Z",
     "shell.execute_reply.started": "2025-08-28T08:32:54.997545Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Modified Training Procedure\n",
    "def train_model(data, run, ratio):\n",
    "\n",
    "    SEED = 42 + run  # Different seed for each run but deterministic\n",
    "    torch.manual_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    # Stratified splitting\n",
    "    labels = data.y.cpu().numpy()\n",
    "    indices = np.arange(len(labels))\n",
    "    \n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=1-ratio, random_state=run)\n",
    "    train_idx, temp_idx = next(sss.split(indices, labels))\n",
    "    \n",
    "    sss_temp = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=run)\n",
    "    val_idx, test_idx = next(sss_temp.split(temp_idx, labels[temp_idx]))\n",
    "    \n",
    "    # Create masks\n",
    "    train_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "    \n",
    "    train_mask[train_idx] = True\n",
    "    val_mask[temp_idx[val_idx]] = True\n",
    "    test_mask[temp_idx[test_idx]] = True\n",
    "    \n",
    "    data.train_mask = train_mask.to(device)\n",
    "    data.val_mask = val_mask.to(device)\n",
    "    data.test_mask = test_mask.to(device)\n",
    "\n",
    "    hidden_channels=64\n",
    "\n",
    "    hidden_channels = min(256, data.num_nodes // 50)  # Example adaptive sizing\n",
    "    model = DyC_DGNN(\n",
    "        in_channels=data.num_features,\n",
    "        hidden_channels=hidden_channels,\n",
    "        out_channels=int(data.y.max()) + 1,\n",
    "        time_steps=5\n",
    "    ).to(device)\n",
    "\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)\n",
    "    \n",
    "    # Store graph data in model for contrastive learning\n",
    "    model.x = data.x  # Add this line\n",
    "    model.edge_index = data.edge_index  # Add this line\n",
    "    \n",
    "    # Training loop with dynamic contrastive learning\n",
    "    best_val_f1 = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits, proj = model(data.x, data.edge_index)\n",
    "        loss = model.full_loss(logits, data.y, proj, data.edge_index, data.train_mask)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Validation and testing\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            logits, _ = model(data.x, data.edge_index)\n",
    "            pred = logits.argmax(dim=1)\n",
    "            \n",
    "            # Calculate validation F1\n",
    "            val_f1 = f1_score(data.y[data.val_mask].cpu(), \n",
    "                            pred[data.val_mask].cpu(),\n",
    "                            average='macro')\n",
    "            \n",
    "            # Early stopping check\n",
    "            if val_f1 > best_val_f1:\n",
    "                best_val_f1 = val_f1\n",
    "                best_model = model.state_dict()\n",
    "                # Calculate test F1\n",
    "                test_f1 = f1_score(data.y[data.test_mask].cpu(),\n",
    "                                 pred[data.test_mask].cpu(),\n",
    "                                 average='macro')\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model)\n",
    "    return test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-28T08:33:00.806751Z",
     "iopub.status.busy": "2025-08-28T08:33:00.806472Z",
     "iopub.status.idle": "2025-08-28T08:33:00.821052Z",
     "shell.execute_reply": "2025-08-28T08:33:00.820137Z",
     "shell.execute_reply.started": "2025-08-28T08:33:00.806728Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_ratios' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31/1133105435.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_ratios\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtraining_ratios\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n=== Training Ratio {ratio*100}% ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtest_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_ratios' is not defined"
     ]
    }
   ],
   "source": [
    "results = {ratio: [] for ratio in training_ratios}\n",
    "for ratio in training_ratios:\n",
    "    print(f\"\\n=== Training Ratio {ratio*100}% ===\")\n",
    "    for run in range(num_runs):\n",
    "        test_f1 = train_model(data, run, ratio)\n",
    "        results[ratio].append(test_f1)\n",
    "        print(f\"Run {run+1}: Test Macro-F1 = {test_f1:.4f}\")\n",
    "\n",
    "# Final reporting\n",
    "print(\"\\nFinal Results (Macro-F1  Std):\")\n",
    "for ratio in training_ratios:\n",
    "    f1_scores = results[ratio]\n",
    "    mean = np.mean(f1_scores)\n",
    "    std = np.std(f1_scores)\n",
    "    print(f\"{ratio*100}% Training: {mean:.2f}  {std:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Contrastive_Spiking_Graph_NeuralNetwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
